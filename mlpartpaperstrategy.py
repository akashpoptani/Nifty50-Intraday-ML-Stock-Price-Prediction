# -*- coding: utf-8 -*-
"""MLPartPaperStrategy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MRd63KboQGH85xZV0zANNSETBQmRUUoE
"""

# Implementation COMMON
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor

import pandas as pd
import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
stocknames = ["RELIANCE","TCS","HDFCBANK","ICICIBANK","INFY","BHARTIARTL","HINDUNILVR","ITC","SBIN","LT"]
#stocknames = ["RELIANCE","TCS","HDFCBANK"]

numtests = 790 #assuming 20% test data and rest 80% training data
total_prediction_graph = []
total_actual_graph = []
for j in range(0, numtests):
    total_actual_graph.append(0)
for _ in range(6):
    inner_list = [0] * numtests
    total_prediction_graph.append(inner_list)

for stockname in stocknames:
  # Load the CSV file
  file_path = f'/content/drive/MyDrive/StockPredStrategies/{stockname}.NS.csv'
  df = pd.read_csv(file_path)

  for i in range(1, df.shape[0]):
      for j in range(df.shape[1]):
          # Check if the value is null
          if pd.isnull(df.iloc[i, j]):
              # Replace null value with the mean of the values in the previous row and the same column
              df.iloc[i, j] = df.iloc[i - 1, j]
  numtests = 790
  numtests = numtests-1 #assuming 20% test data and rest 80% training data
  # Split the data into training and testing sets
  train_data = []
  train_data = df.iloc[1:-numtests+1]  #rows 2 to 3021
  test_data = df.iloc[-numtests-1:]    # rows 3022 to the end

  print(train_data)
  print(test_data.shape)

  # features=['Open']
  from sklearn.linear_model import LinearRegression
  #topredict = ['Adj Close', 'High', 'Low']
  topredict = ['Adj Close']
  prediction_graph = []
  modelname_graph = []
  actual_values = []

  features=['Open', 'Adj Close', 'High', 'Low']
  pandasdataframe = pd.DataFrame(train_data, columns=features)
  # print(pandasdataframe)
  # print(df.iloc[1:-numtests+2]['Open'][1:])
  ls=df.iloc[1:-numtests+2]['Open'][1:]
  # pandasdataframe['NextOpen'] = ls.values
  # print(pandasdataframe)
  testdataframe=pd.DataFrame(test_data, columns=features)
  # print(testdataframe)
  # print(df.iloc[-numtests-2:]['Open'][1:])
  ls=df.iloc[-numtests-2:]['Open'][1:]
  # testdataframe['NextOpen'] = ls.values
  # print(testdataframe)

  # Function to train and evaluate a model
  def train_and_evaluate_model(model, model_name, variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe):
      actual_values = test_data[variable][-numtests-1:]
      #print(f"Actual values for {variable}: {actual_values.shape}")
      model.fit(pandasdataframe[:-1], train_data[variable][1:])
      predictions = model.predict(testdataframe)

      # # Train the model
      # model.fit(pd.DataFrame(train_data, columns=features), train_data[variable])

      # # Make predictions on the test data
      # predictions = model.predict(test_data[features])

      #print(f"Predictions for {variable}: {predictions.shape}")

      # Calculate evaluation metrics on the test data
      mae = mean_absolute_error(actual_values, predictions)
      mse = mean_squared_error(actual_values, predictions)
      r2 = r2_score(actual_values, predictions)

      print(f'{variable} - MAE: {mae}')
      print(f'{variable} - MSE: {mse}')
      print(f'{variable} - R2 Score: {r2}')

      prediction_graph.append(predictions)
      modelname_graph.append(model_name)
      print(model_name)

  # from sklearn.linear_model import LinearRegression
  # from sklearn.svm import SVR
  # from sklearn.neighbors import KNeighborsRegressor
  # from sklearn.tree import DecisionTreeRegressor
  # from sklearn.ensemble import RandomForestRegressor

  # Loop over each variable in topredict
  for variable in topredict:
      # Linear Regression Model
      lr_model = LinearRegression()
      train_and_evaluate_model(lr_model, 'Linear Regression', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # Support Vector Machine Model
      svm_model = SVR()
      train_and_evaluate_model(svm_model, 'Support Vector Machine', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # Support Vector Machine Model with Initialization to y=x function
      C_value = 1.0  # Regularization parameter
      kernel_type = 'linear'  # Use 'linear' kernel for y=x function
      epsilon_value = 0.1  # Epsilon in the epsilon-SVR model
      svm_model = SVR(C=C_value, kernel=kernel_type, epsilon=epsilon_value, max_iter=500000)
      train_and_evaluate_model(svm_model, 'SVR (y=x)', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # K-Nearest Neighbors
      knn_model = KNeighborsRegressor(n_neighbors=5)
      train_and_evaluate_model(knn_model, 'K-Nearest Neighbors', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # Decision Tree Model
      dt_model = DecisionTreeRegressor()
      train_and_evaluate_model(dt_model, 'Decision Tree', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # Random Forest Model
      rf_model = RandomForestRegressor()
      train_and_evaluate_model(rf_model, 'Random Forest', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # Additional step for the last variable
      actual_values = test_data[variable][-numtests-1:]
      dummylist = [values for values in actual_values]

      maxactualvalue = max(actual_values)
      for var in range(0,6):
        for i in range(0,numtests+1):
          prediction_graph[var][i]=prediction_graph[var][i]/maxactualvalue
          total_prediction_graph[var][i] = total_prediction_graph[var][i] + prediction_graph[var][i]
      for j in range(0,numtests+1):
        dummylist[j] = dummylist[j]/maxactualvalue
        total_actual_graph[j]  = total_actual_graph[j] + dummylist[j]
      actual_values = [value / maxactualvalue for value in actual_values]

      # Plot actual vs predicted values on the test data
      plt.figure(figsize=(10, 6))
      plt.plot(range(0, numtests+1), actual_values, label='Actual')
      plt.plot(range(0, numtests+1), prediction_graph[0], label=f'{modelname_graph[0]} Predicted')
      plt.plot(range(0, numtests+1), prediction_graph[1], label=f'{modelname_graph[1]} Predicted')
      plt.plot(range(0, numtests+1), prediction_graph[2], label=f'{modelname_graph[2]} Predicted')
      plt.plot(range(0, numtests+1), prediction_graph[3], label=f'{modelname_graph[3]} Predicted')
      plt.plot(range(0, numtests+1), prediction_graph[4], label=f'{modelname_graph[4]} Predicted')
      plt.plot(range(0, numtests+1), prediction_graph[5], label=f'{modelname_graph[5]} Predicted')
      #plt.title(f'{variable} - Normalised - {stockname} - Actual vs Predicted ')
      plt.xlabel('Time')
      plt.ylabel(f'{variable} Price')
      plt.legend()

      # Show the plot
      plt.savefig(f'{variable}_MLPred_{stockname}.pdf')

import csv

# Create a list to store the results for each variable
results_list = []

for i in range(6):
    # Calculate evaluation metrics on the test data
    mae = mean_absolute_error(total_actual_graph, total_prediction_graph[i])
    mse = mean_squared_error(total_actual_graph, total_prediction_graph[i])
    r2 = r2_score(total_actual_graph, total_prediction_graph[i])

    # Append results to the list
    results_list.append({'mae': mae, 'mse': mse, 'r2_score': r2})

# Write results to a CSV file
csv_filename = f'{variable}_results.csv'
with open(csv_filename, 'w', newline='') as csvfile:
    fieldnames = ['mae', 'mse', 'r2_score']
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

    # Write header
    writer.writeheader()

    # Write results for each variable
    for result in results_list:
        writer.writerow(result)

print(f"Results written to {csv_filename}.")

# Plot actual vs predicted values on the test data
plt.figure(figsize=(10, 6))
plt.plot(range(0, numtests+1), total_actual_graph, label='Actual')
plt.plot(range(0, numtests+1), total_prediction_graph[0], label=f'{modelname_graph[0]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[1], label=f'{modelname_graph[1]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[2], label=f'{modelname_graph[2]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[3], label=f'{modelname_graph[3]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[4], label=f'{modelname_graph[4]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[5], label=f'{modelname_graph[5]} ', linestyle='--')
#plt.title(f'{variable} - Overall - NORMALISED - Actual vs Predicted')
plt.xlabel('Time')
plt.ylabel(f'{variable} Price')
plt.legend()

# Show the plot
plt.savefig(f'{variable}_MLPred_NORMALISED_Overall.pdf')

# Plot actual vs predicted values on the test data
plt.figure(figsize=(15, 5))
plt.plot(range(0, numtests+1), total_actual_graph, label='Actual')
plt.plot(range(0, numtests+1), total_prediction_graph[0], label=f'{modelname_graph[0]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[1], label=f'{modelname_graph[1]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[2], label=f'{modelname_graph[2]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[3], label=f'{modelname_graph[3]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[4], label=f'{modelname_graph[4]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[5], label=f'{modelname_graph[5]} ', linestyle='--')
#plt.title(f'Legend update -{variable} - Overall - NORMALISED - Actual vs Predicted')
plt.xlabel('Time')
plt.ylabel(f'{variable} Price')
plt.legend(loc='center left', bbox_to_anchor=(0.8, 0.3))

# Show the plot
plt.savefig(f'Legend - {variable}_MLPred_NORMALISED_Overall.pdf')

#HIGH - Part
numtests = 790 #assuming 20% test data and rest 80% training data
total_prediction_graph = []
total_actual_graph = []
for j in range(0, numtests):
    total_actual_graph.append(0)
for _ in range(6):
    inner_list = [0] * numtests
    total_prediction_graph.append(inner_list)

for stockname in stocknames:
  # Load the CSV file
  file_path = f'/content/drive/MyDrive/StockPredStrategies/{stockname}.NS.csv'
  df = pd.read_csv(file_path)

  for i in range(1, df.shape[0]):
      for j in range(df.shape[1]):
          # Check if the value is null
          if pd.isnull(df.iloc[i, j]):
              # Replace null value with the mean of the values in the previous row and the same column
              df.iloc[i, j] = df.iloc[i - 1, j]
  numtests = 790
  numtests = numtests-1 #assuming 20% test data and rest 80% training data
  # Split the data into training and testing sets
  train_data = []
  train_data = df.iloc[1:-numtests+1]  #rows 2 to 3021
  test_data = df.iloc[-numtests-1:]    # rows 3022 to the end

  print(train_data)
  print(test_data.shape)

  # features=['Open']
  from sklearn.linear_model import LinearRegression
  #topredict = ['Adj Close', 'High', 'Low']
  topredict = ['High']
  prediction_graph = []
  modelname_graph = []
  actual_values = []

  features=['Open', 'Adj Close', 'High', 'Low']
  pandasdataframe = pd.DataFrame(train_data, columns=features)
  # print(pandasdataframe)
  # print(df.iloc[1:-numtests+2]['Open'][1:])
  ls=df.iloc[1:-numtests+2]['Open'][1:]
  # pandasdataframe['NextOpen'] = ls.values
  # print(pandasdataframe)
  testdataframe=pd.DataFrame(test_data, columns=features)
  # print(testdataframe)
  # print(df.iloc[-numtests-2:]['Open'][1:])
  ls=df.iloc[-numtests-2:]['Open'][1:]
  # testdataframe['NextOpen'] = ls.values
  # print(testdataframe)

  # Function to train and evaluate a model
  def train_and_evaluate_model(model, model_name, variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe):
      actual_values = test_data[variable][-numtests-1:]
      #print(f"Actual values for {variable}: {actual_values.shape}")
      model.fit(pandasdataframe[:-1], train_data[variable][1:])
      predictions = model.predict(testdataframe)

      # # Train the model
      # model.fit(pd.DataFrame(train_data, columns=features), train_data[variable])

      # # Make predictions on the test data
      # predictions = model.predict(test_data[features])

      #print(f"Predictions for {variable}: {predictions.shape}")

      # Calculate evaluation metrics on the test data
      mae = mean_absolute_error(actual_values, predictions)
      mse = mean_squared_error(actual_values, predictions)
      r2 = r2_score(actual_values, predictions)

      print(f'{variable} - MAE: {mae}')
      print(f'{variable} - MSE: {mse}')
      print(f'{variable} - R2 Score: {r2}')

      prediction_graph.append(predictions)
      modelname_graph.append(model_name)
      print(model_name)

  # from sklearn.linear_model import LinearRegression
  # from sklearn.svm import SVR
  # from sklearn.neighbors import KNeighborsRegressor
  # from sklearn.tree import DecisionTreeRegressor
  # from sklearn.ensemble import RandomForestRegressor

  # Loop over each variable in topredict
  for variable in topredict:
      # Linear Regression Model
      lr_model = LinearRegression()
      train_and_evaluate_model(lr_model, 'Linear Regression', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # Support Vector Machine Model
      svm_model = SVR()
      train_and_evaluate_model(svm_model, 'Support Vector Machine', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # Support Vector Machine Model with Initialization to y=x function
      C_value = 1.0  # Regularization parameter
      kernel_type = 'linear'  # Use 'linear' kernel for y=x function
      epsilon_value = 0.1  # Epsilon in the epsilon-SVR model
      svm_model = SVR(C=C_value, kernel=kernel_type, epsilon=epsilon_value, max_iter=500000)
      train_and_evaluate_model(svm_model, 'SVR (y=x)', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # K-Nearest Neighbors
      knn_model = KNeighborsRegressor(n_neighbors=5)
      train_and_evaluate_model(knn_model, 'K-Nearest Neighbors', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # Decision Tree Model
      dt_model = DecisionTreeRegressor()
      train_and_evaluate_model(dt_model, 'Decision Tree', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # Random Forest Model
      rf_model = RandomForestRegressor()
      train_and_evaluate_model(rf_model, 'Random Forest', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # Additional step for the last variable
      actual_values = test_data[variable][-numtests-1:]
      dummylist = [values for values in actual_values]

      maxactualvalue = max(actual_values)
      for var in range(0,6):
        for i in range(0,numtests+1):
          prediction_graph[var][i]=prediction_graph[var][i]/maxactualvalue
          total_prediction_graph[var][i] = total_prediction_graph[var][i] + prediction_graph[var][i]
      for j in range(0,numtests+1):
        dummylist[j] = dummylist[j]/maxactualvalue
        total_actual_graph[j]  = total_actual_graph[j] + dummylist[j]
      actual_values = [value / maxactualvalue for value in actual_values]

      # Plot actual vs predicted values on the test data
      plt.figure(figsize=(10, 6))
      plt.plot(range(0, numtests+1), actual_values, label='Actual')
      plt.plot(range(0, numtests+1), prediction_graph[0], label=f'{modelname_graph[0]} Predicted')
      plt.plot(range(0, numtests+1), prediction_graph[1], label=f'{modelname_graph[1]} Predicted')
      plt.plot(range(0, numtests+1), prediction_graph[2], label=f'{modelname_graph[2]} Predicted')
      plt.plot(range(0, numtests+1), prediction_graph[3], label=f'{modelname_graph[3]} Predicted')
      plt.plot(range(0, numtests+1), prediction_graph[4], label=f'{modelname_graph[4]} Predicted')
      plt.plot(range(0, numtests+1), prediction_graph[5], label=f'{modelname_graph[5]} Predicted')
      plt.title(f'{variable} - Normalised - {stockname} - Actual vs Predicted ')
      plt.xlabel('Time')
      plt.ylabel(f'{variable} Price')
      plt.legend()

      # Show the plot
      plt.savefig(f'{variable}_MLPred_{stockname}.pdf')

import csv

# Create a list to store the results for each variable
results_list = []

for i in range(6):
    # Calculate evaluation metrics on the test data
    mae = mean_absolute_error(total_actual_graph, total_prediction_graph[i])
    mse = mean_squared_error(total_actual_graph, total_prediction_graph[i])
    r2 = r2_score(total_actual_graph, total_prediction_graph[i])

    # Append results to the list
    results_list.append({'mae': mae, 'mse': mse, 'r2_score': r2})

# Write results to a CSV file
csv_filename = f'{variable}_results.csv'
with open(csv_filename, 'w', newline='') as csvfile:
    fieldnames = ['mae', 'mse', 'r2_score']
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

    # Write header
    writer.writeheader()

    # Write results for each variable
    for result in results_list:
        writer.writerow(result)

print(f"Results written to {csv_filename}.")

# Plot actual vs predicted values on the test data
plt.figure(figsize=(10, 6))
plt.plot(range(0, numtests+1), total_prediction_graph[0], label=f'{modelname_graph[0]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[1], label=f'{modelname_graph[1]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[2], label=f'{modelname_graph[2]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[3], label=f'{modelname_graph[3]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[4], label=f'{modelname_graph[4]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[5], label=f'{modelname_graph[5]} ', linestyle='--')
#plt.title(f'{variable} - Overall - NORMALISED - Actual vs Predicted')
plt.xlabel('Time')
plt.ylabel(f'{variable} Price')
plt.legend()

# Show the plot
plt.savefig(f'{variable}_MLPred_NORMALISED_Overall.pdf')

# Plot actual vs predicted values on the test data
plt.figure(figsize=(15, 5))
plt.plot(range(0, numtests+1), total_actual_graph, label='Actual')
plt.plot(range(0, numtests+1), total_prediction_graph[0], label=f'{modelname_graph[0]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[1], label=f'{modelname_graph[1]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[2], label=f'{modelname_graph[2]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[3], label=f'{modelname_graph[3]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[4], label=f'{modelname_graph[4]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[5], label=f'{modelname_graph[5]} ', linestyle='--')
#plt.title(f'Legend update -{variable} - Overall - NORMALISED - Actual vs Predicted')
plt.xlabel('Time')
plt.ylabel(f'{variable} Price')
plt.legend(loc='center left', bbox_to_anchor=(0.8, 0.3))

# Show the plot
plt.savefig(f'Legend - {variable}_MLPred_NORMALISED_Overall.pdf')

# Plot actual vs predicted values on the test data
plt.figure(figsize=(15, 5))
plt.plot(range(0, numtests+1), total_actual_graph, label='Actual')
plt.plot(range(0, numtests+1), total_prediction_graph[0], label=f'{modelname_graph[0]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[1], label=f'{modelname_graph[1]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[2], label=f'{modelname_graph[2]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[3], label=f'{modelname_graph[3]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[4], label=f'{modelname_graph[4]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[5], label=f'{modelname_graph[5]} ', linestyle='--')
#plt.title(f'Legend update -{variable} - Overall - NORMALISED - Actual vs Predicted')
plt.xlabel('Time')
plt.ylabel(f'{variable} Price')
plt.legend(loc='center left', bbox_to_anchor=(0.8, 0.3))

# Show the plot
plt.savefig(f'Legend - {variable}_MLPred_NORMALISED_Overall.pdf')

#LOW part
numtests = 790 #assuming 20% test data and rest 80% training data
total_prediction_graph = []
total_actual_graph = []
for j in range(0, numtests):
    total_actual_graph.append(0)
for _ in range(6):
    inner_list = [0] * numtests
    total_prediction_graph.append(inner_list)

for stockname in stocknames:
  # Load the CSV file
  file_path = f'/content/drive/MyDrive/StockPredStrategies/{stockname}.NS.csv'
  df = pd.read_csv(file_path)

  for i in range(1, df.shape[0]):
      for j in range(df.shape[1]):
          # Check if the value is null
          if pd.isnull(df.iloc[i, j]):
              # Replace null value with the mean of the values in the previous row and the same column
              df.iloc[i, j] = df.iloc[i - 1, j]
  numtests = 790
  numtests = numtests-1 #assuming 20% test data and rest 80% training data
  # Split the data into training and testing sets
  train_data = []
  train_data = df.iloc[1:-numtests+1]  #rows 2 to 3021
  test_data = df.iloc[-numtests-1:]    # rows 3022 to the end

  print(train_data)
  print(test_data.shape)

  # features=['Open']
  from sklearn.linear_model import LinearRegression
  #topredict = ['Adj Close', 'High', 'Low']
  topredict = ['Low']
  prediction_graph = []
  modelname_graph = []
  actual_values = []

  features=['Open', 'Adj Close', 'High', 'Low']
  pandasdataframe = pd.DataFrame(train_data, columns=features)
  # print(pandasdataframe)
  # print(df.iloc[1:-numtests+2]['Open'][1:])
  ls=df.iloc[1:-numtests+2]['Open'][1:]
  # pandasdataframe['NextOpen'] = ls.values
  # print(pandasdataframe)
  testdataframe=pd.DataFrame(test_data, columns=features)
  # print(testdataframe)
  # print(df.iloc[-numtests-2:]['Open'][1:])
  ls=df.iloc[-numtests-2:]['Open'][1:]
  # testdataframe['NextOpen'] = ls.values
  # print(testdataframe)

  # Function to train and evaluate a model
  def train_and_evaluate_model(model, model_name, variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe):
      actual_values = test_data[variable][-numtests-1:]
      #print(f"Actual values for {variable}: {actual_values.shape}")
      model.fit(pandasdataframe[:-1], train_data[variable][1:])
      predictions = model.predict(testdataframe)

      # # Train the model
      # model.fit(pd.DataFrame(train_data, columns=features), train_data[variable])

      # # Make predictions on the test data
      # predictions = model.predict(test_data[features])

      #print(f"Predictions for {variable}: {predictions.shape}")

      # Calculate evaluation metrics on the test data
      mae = mean_absolute_error(actual_values, predictions)
      mse = mean_squared_error(actual_values, predictions)
      r2 = r2_score(actual_values, predictions)

      print(f'{variable} - MAE: {mae}')
      print(f'{variable} - MSE: {mse}')
      print(f'{variable} - R2 Score: {r2}')

      prediction_graph.append(predictions)
      modelname_graph.append(model_name)
      print(model_name)

  # from sklearn.linear_model import LinearRegression
  # from sklearn.svm import SVR
  # from sklearn.neighbors import KNeighborsRegressor
  # from sklearn.tree import DecisionTreeRegressor
  # from sklearn.ensemble import RandomForestRegressor

  # Loop over each variable in topredict
  for variable in topredict:
      # Linear Regression Model
      lr_model = LinearRegression()
      train_and_evaluate_model(lr_model, 'Linear Regression', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # Support Vector Machine Model
      svm_model = SVR()
      train_and_evaluate_model(svm_model, 'Support Vector Machine', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # Support Vector Machine Model with Initialization to y=x function
      C_value = 1.0  # Regularization parameter
      kernel_type = 'linear'  # Use 'linear' kernel for y=x function
      epsilon_value = 0.1  # Epsilon in the epsilon-SVR model
      svm_model = SVR(C=C_value, kernel=kernel_type, epsilon=epsilon_value, max_iter=500000)
      train_and_evaluate_model(svm_model, 'SVR (y=x)', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # K-Nearest Neighbors
      knn_model = KNeighborsRegressor(n_neighbors=5)
      train_and_evaluate_model(knn_model, 'K-Nearest Neighbors', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # Decision Tree Model
      dt_model = DecisionTreeRegressor()
      train_and_evaluate_model(dt_model, 'Decision Tree', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # Random Forest Model
      rf_model = RandomForestRegressor()
      train_and_evaluate_model(rf_model, 'Random Forest', variable, train_data, test_data, features, numtests,pandasdataframe,testdataframe)

      # Additional step for the last variable
      actual_values = test_data[variable][-numtests-1:]
      dummylist = [values for values in actual_values]

      maxactualvalue = max(actual_values)
      for var in range(0,6):
        for i in range(0,numtests+1):
          prediction_graph[var][i]=prediction_graph[var][i]/maxactualvalue
          total_prediction_graph[var][i] = total_prediction_graph[var][i] + prediction_graph[var][i]
      for j in range(0,numtests+1):
        dummylist[j] = dummylist[j]/maxactualvalue
        total_actual_graph[j]  = total_actual_graph[j] + dummylist[j]
      actual_values = [value / maxactualvalue for value in actual_values]

      # Plot actual vs predicted values on the test data
      plt.figure(figsize=(10, 6))
      plt.plot(range(0, numtests+1), actual_values, label='Actual')
      plt.plot(range(0, numtests+1), prediction_graph[0], label=f'{modelname_graph[0]} Predicted')
      plt.plot(range(0, numtests+1), prediction_graph[1], label=f'{modelname_graph[1]} Predicted')
      plt.plot(range(0, numtests+1), prediction_graph[2], label=f'{modelname_graph[2]} Predicted')
      plt.plot(range(0, numtests+1), prediction_graph[3], label=f'{modelname_graph[3]} Predicted')
      plt.plot(range(0, numtests+1), prediction_graph[4], label=f'{modelname_graph[4]} Predicted')
      plt.plot(range(0, numtests+1), prediction_graph[5], label=f'{modelname_graph[5]} Predicted')
      plt.title(f'{variable} - Normalised - {stockname} - Actual vs Predicted ')
      plt.xlabel('Time')
      plt.ylabel(f'{variable} Price')
      plt.legend()

      # Show the plot
      plt.savefig(f'{variable}_MLPred_{stockname}.pdf')

import csv

# Create a list to store the results for each variable
results_list = []

for i in range(6):
    # Calculate evaluation metrics on the test data
    mae = mean_absolute_error(total_actual_graph, total_prediction_graph[i])
    mse = mean_squared_error(total_actual_graph, total_prediction_graph[i])
    r2 = r2_score(total_actual_graph, total_prediction_graph[i])

    # Append results to the list
    results_list.append({'mae': mae, 'mse': mse, 'r2_score': r2})

# Write results to a CSV file
csv_filename = f'{variable}_results.csv'
with open(csv_filename, 'w', newline='') as csvfile:
    fieldnames = ['mae', 'mse', 'r2_score']
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

    # Write header
    writer.writeheader()

    # Write results for each variable
    for result in results_list:
        writer.writerow(result)

print(f"Results written to {csv_filename}.")

# Plot actual vs predicted values on the test data
plt.figure(figsize=(10, 6))
plt.plot(range(0, numtests+1), total_actual_graph, label='Actual')
plt.plot(range(0, numtests+1), total_prediction_graph[0], label=f'{modelname_graph[0]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[1], label=f'{modelname_graph[1]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[2], label=f'{modelname_graph[2]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[3], label=f'{modelname_graph[3]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[4], label=f'{modelname_graph[4]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[5], label=f'{modelname_graph[5]} ', linestyle='--')
#plt.title(f'{variable} - Overall - NORMALISED - Actual vs Predicted')
plt.xlabel('Time')
plt.ylabel(f'{variable} Price')
plt.legend()

# Show the plot
plt.savefig(f'{variable}_MLPred_NORMALISED_Overall.pdf')

# Plot actual vs predicted values on the test data
plt.figure(figsize=(15, 5))
plt.plot(range(0, numtests+1), total_actual_graph, label='Actual')
plt.plot(range(0, numtests+1), total_prediction_graph[0], label=f'{modelname_graph[0]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[1], label=f'{modelname_graph[1]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[2], label=f'{modelname_graph[2]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[3], label=f'{modelname_graph[3]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[4], label=f'{modelname_graph[4]} ', linestyle='--')
plt.plot(range(0, numtests+1), total_prediction_graph[5], label=f'{modelname_graph[5]} ', linestyle='--')
#plt.title(f'Legend update -{variable} - Overall - NORMALISED - Actual vs Predicted')
plt.xlabel('Time')
plt.ylabel(f'{variable} Price')
plt.legend(loc='center left', bbox_to_anchor=(0.8, 0.3))

# Show the plot
plt.savefig(f'Legend - {variable}_MLPred_NORMALISED_Overall.pdf')